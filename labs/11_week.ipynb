{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a821562c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "options(jupyter.rich_display = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685c5a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 11 Tutorial: Complexity and Performance\n",
    "\n",
    "## POP77001 Computer Programming for Social Scientists\n",
    "\n",
    "##### Module website: [bit.ly/POP77001](https://bit.ly/POP77001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eab92e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Benchmarking in R\n",
    "\n",
    "- In the lecture we used `system.time()` function to analyse function performance\n",
    "- Albeit conveniently built-in, the main drawback is that it's rather coarse\n",
    "- While useful for detecting large performance gaps, it often doesn't capture more subtle differences\n",
    "- The reason is that it only runs once and uses seconds as a standard unit of measurement\n",
    "- Here we will use `microbenchmark` package and identically named function to time function calls\n",
    "- Remember to print out the results of `microbenchmark`, otherwise times of individual runs are returnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c4cd65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "library(\"microbenchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b564d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1: Compare performance\n",
    "\n",
    "- Consider a data frame with 20 different variables below\n",
    "- We want to know the mean of each variable in the matrix\n",
    "- There are 2 principal ways of estimating them\n",
    "- One using `apply()` function (as in Week 9)\n",
    "- Or using built-in `colMeans()` function\n",
    "- Apply each of those function to calculate means\n",
    "- Benchmark the time it took to run using `system.time` and `microbenchmark`\n",
    "- What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bd5d82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(2021)\n",
    "# Here we create a data frame of 1000 observations of 50 variables\n",
    "# where each variable is a random draw from a normal distribution with mean\n",
    "# drawn from a uniform distribution between 0 and 10 and standard deviation 1\n",
    "dat <- data.frame(mapply(\n",
    "  function(x) cbind(rnorm(n = 1000, mean = x, sd = 1)),\n",
    "  runif(n = 50, min = 0, max = 10)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a35657",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1000   50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2955b06",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Benchmarking in Python\n",
    "\n",
    "- It is possible to measure timing of operation in Python with built-in `time` module\n",
    "- But it would require recording time before a call and after and then taking a difference\n",
    "- Python's built-in `timeit` module provides a better alternative as it does it automatically an more\n",
    "- It behaves similar to `microbenchmark` in R in that it averages over many runs\n",
    "- It is also available in IPython (and, as a result, in Jupyter) as a magic command that can be called with `%timeit`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59860c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Switching kernels in Jupyter\n",
    "\n",
    "- In order to be able to continue with Python part of the exercises you can switch your kernel\n",
    "- Got to `Kernel`, `Change kernel` and pick Python from the drop-down menu\n",
    "\n",
    "![Jupyter Notebook Change Kernel](../imgs/jupyter_notebook_switch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3852666",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07caeae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7261368325293743"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random numbers in Python can be generated either using\n",
    "# the built-in `random` module or using `numpy` external\n",
    "# module (which is underlying a lot of `pandas` operations)\n",
    "random.gauss(mu = 0, sigma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02364bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.88354514])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of just a float number it returns an array\n",
    "np.random.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c4f132",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's start our benchmarking experiments from looking\n",
    "# at random number generation in Python.\n",
    "# First let's draw a sample of 1M using both built-in `random` module\n",
    "# And `numpy`'s methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49ab4b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40fb9635",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 ms ± 2.62 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# We can use `for _` expression to inicate that returned value is being discarded\n",
    "%timeit [random.gauss(mu = 0, sigma = 1) for _ in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4487e2f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2 ms ± 99.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# `numpy` is order of magnitude faster than built-in module\n",
    "%timeit np.random.normal(size = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8bb926",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 2: \n",
    "\n",
    "- Now let's replicate the calculation of some summary statistics in `pandas` DataFrame\n",
    "- As in the case of R, there are 2 principal ways of doing this\n",
    "- First, is iterating over columns in a data set with a list comprehension\n",
    "- And applying some function to each of columns (e.g. `mean()` from `statistics` module)\n",
    "- Alternatively, you can apply one of the built-in statistical summary methods (check Week 5 for a list)\n",
    "- Apply each of those approaches to a data frame below\n",
    "- How do these two approaches compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa205c41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d19d86f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Here we are, essnetially, replicating the process of data frame creation as in R above\n",
    "# each variable is a random draw from a normal distribution with mean\n",
    "# drawn from a uniform distribution between 0 and 10 and standard deviation 1\n",
    "dat2 = pd.DataFrame(np.concatenate([\n",
    "    np.random.normal(loc = x, scale = 1, size = (1000, 1))\n",
    "     for x\n",
    "     in np.random.uniform(low = 0, high = 10, size = 50)\n",
    "], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a4f37b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a37335",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Week 11: Assignment 5\n",
    "\n",
    "- Practice order of growth calculation, benchmarking and data wrangling\n",
    "- Due at 11:00 on Monday, 29th November"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
